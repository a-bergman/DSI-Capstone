{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import seaborn               as sns\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.metrics         import r2_score\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from IPython.core.display    import display, HTML\n",
    "sns.set(style = \"white\", palette = \"husl\")\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Contents\n",
    "\n",
    "-----\n",
    "\n",
    "1. [Reading In The Data](#Reading-In-The-Data)\n",
    "    - [Overview](#Overview)\n",
    "\n",
    "-----\n",
    "\n",
    "2. [Feature Engineering](#Feature-Engineering)\n",
    "    - [Transforming Numeric Data](#Transforming-Numeric-Data)\n",
    "    - [Creating Segmental Features](#Creating-Areal-Features)\n",
    "    - [Implementing The Pattern Sub-Model Approach](#Implementing-The-Pattern-Sub-Model-Approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = pd.read_csv(\"../Data/mri_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `smoker_status` column is still in the data, but we will not needing the column for the models because we turned it into a pair of dummy columns so we will drop the column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dropping `smoker_status`\n",
    "\n",
    "mri = mri.drop(\"smoker_status\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the data\n",
    "\n",
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of column data types\n",
    "\n",
    "mri.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for columns with missing/NaN data\n",
    "\n",
    "(mri.isnull().mean()*100).sort_values(ascending = False).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Numeric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only four numeric columns in the data set: `age`, `lvesv`, `lvedv`, `lvef`.  Of the four, only `lvef` does not have any kind of a normal distribution: `age` is close to normally distributed, while `lvesv` and `lvedv` are log-normally distributed.\n",
    "\n",
    "We cannot do anything to `lvedv` because that is my target variable, but we can take the log of `lvesv` (in this case the natural log).  We also tried squaring `age` but that did not affect the distribution in the way we hoped it would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the natural log of `lvesv`.\n",
    "# We chose to make it it's own column rather\n",
    "# than overwrite the column.\n",
    "\n",
    "mri[\"lvesv_log\"] = mri[\"lvesv\"].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-Of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Segmental Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the model attempts to predict the end diastolic volume, we want it to be as accurate as it can be.  As part of that, we will try to use many combinations of features in an attempt to achieve high accuracy.\n",
    "\n",
    "The data have 34 columns that we wish to engineer: a column measuring scarification and a column measuring ischemia.  Because there are so many of them, we felt the need to experiment with how they are passed into the model.  We are unable to create interaction columns, because there are zeros.  Instead, we elected to create segmental columns by summing similar columns together: we will compare the model's performance with the originals and with the segmental columns.\n",
    "\n",
    "We used this image to guide our create of segmental columns:\n",
    "\n",
    "<img src = \"../Images/cardiac-segmentation-for-cardiac-perfusion-defects.jpg\" alt = \"Cardiac Segmentation\" height = 700 width = 700>\n",
    "\n",
    "Case courtesy of Dr Hamid Chalian, <a href=\"https://radiopaedia.org/\">Radiopaedia.org</a>. From the case <a href=\"https://radiopaedia.org/cases/47102\">rID: 47102</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns based off of the red, blue, green, and yellow\n",
    "# I'm combining the apex and apical regions because there is only\n",
    "# one region in the apex.\n",
    "\n",
    "mri[\"basal\"]  = mri[\"ba_he\"] + mri[\"bas_he\"] + mri[\"bis_he\"] \\\n",
    "                + mri[\"bi_he\"] + mri[\"bil_he\"] + mri[\"bal_he\"]\n",
    "mri[\"mid\"]    = mri[\"ma_he\"] + mri[\"mas_he\"] + mri[\"mis_he\"] \\\n",
    "                + mri[\"mi_he\"] + mri[\"mil_he\"] + mri[\"mal_he\"]\n",
    "mri[\"apical\"] = mri[\"aa_he\"] + mri[\"as_he\"] + mri[\"ai_he\"] \\\n",
    "                + mri[\"al_he\"] + mri[\"apex_he\"]\n",
    "\n",
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
