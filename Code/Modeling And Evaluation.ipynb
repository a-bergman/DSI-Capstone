{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                as pd\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import seaborn               as sns\n",
    "from math                    import sqrt\n",
    "from sklearn.linear_model    import LinearRegression\n",
    "from sklearn.linear_model    import LassoCV\n",
    "from sklearn.linear_model    import RidgeCV\n",
    "from sklearn.metrics         import r2_score\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.metrics         import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from IPython.core.display    import display, HTML\n",
    "sns.set(style = \"white\", palette = \"husl\")\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Of Contents\n",
    "\n",
    "-----\n",
    "\n",
    "1. [Reading In The Data](#Reading-In-The-Data)\n",
    "    - [Overview](#Overview)\n",
    "\n",
    "-----\n",
    "\n",
    "2. [Feature Engineering](#Feature-Engineering)\n",
    "    - [Transforming Numeric Data](#Transforming-Numeric-Data)\n",
    "    - [Creating Segmental Features](#Creating-Segmental-Features)\n",
    "    \n",
    "-----\n",
    "\n",
    "3. [Modeling](#Modeling)\n",
    "    - [Functions](#Functions)\n",
    "    - [Linear Regression](#Linear-Regression)\n",
    "    - [Ridge](#Ridge)\n",
    "    - [LASSO](#LASSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading In The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri = pd.read_csv(\"../Data/mri_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `smoker_status` column is still in the data, but we will not needing the column for the models because we turned it into a pair of dummy columns so we will drop the column here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the shape of the data\n",
    "\n",
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of column data types\n",
    "\n",
    "mri.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Numeric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only four numeric columns in the data set: `age`, `lvesv`, `lvedv`, `lvef`.  Of the four, only `lvef` does not have any kind of a normal distribution: `age` is close to normally distributed, while `lvesv` and `lvedv` are log-normally distributed.\n",
    "\n",
    "We cannot do anything to `lvedv` because that is my target variable, but we can take the log of `lvesv` (in this case the natural log).  We also tried squaring `age` but that did not affect the distribution in the way we hoped it would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the natural log of `lvesv`.\n",
    "# We chose to make it it's own column rather\n",
    "# than overwrite the column.\n",
    "\n",
    "mri[\"lvesv_log\"] = mri[\"lvesv\"].apply(lambda x: np.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-Of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Segmental Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the model attempts to predict the end diastolic volume, we want it to be as accurate as it can be.  As part of that, we will try to use many combinations of features in an attempt to achieve high accuracy.\n",
    "\n",
    "The data have 34 columns that we wish to engineer: a column measuring scarification and a column measuring ischemia.  Because there are so many of them, we felt the need to experiment with how they are passed into the model.  We are unable to create interaction columns, because there are zeros.  Instead, we elected to create segmental columns by summing similar columns together: we will compare the model's performance with the originals and with the segmental columns.\n",
    "\n",
    "We used this image to guide our create of segmental columns:\n",
    "\n",
    "<img src = \"../Images/cardiac-segmentation-for-cardiac-perfusion-defects.jpg\" alt = \"Cardiac Segmentation\" height = 750 width = 750>\n",
    "\n",
    "Case courtesy of Dr Hamid Chalian, <a href=\"https://radiopaedia.org/\">Radiopaedia.org</a>. From the case <a href=\"https://radiopaedia.org/cases/47102\">rID: 47102</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns based off of the red, blue, green, and yellow\n",
    "# I'm combining the apex and apical regions because there is only\n",
    "# one region in the apex.\n",
    "\n",
    "# New columns for scar tissue\n",
    "\n",
    "mri[\"basal_he\"]  = mri[\"ba_he\"] + mri[\"bas_he\"] + mri[\"bis_he\"] \\\n",
    "                   + mri[\"bi_he\"] + mri[\"bil_he\"] + mri[\"bal_he\"]\n",
    "mri[\"mid_he\"]    = mri[\"ma_he\"] + mri[\"mas_he\"] + mri[\"mis_he\"] \\\n",
    "                   + mri[\"mi_he\"] + mri[\"mil_he\"] + mri[\"mal_he\"]\n",
    "mri[\"apical_he\"] = mri[\"aa_he\"] + mri[\"as_he\"] + mri[\"ai_he\"] \\\n",
    "                   + mri[\"al_he\"] + mri[\"apex_he\"]\n",
    "\n",
    "# New columns for ischemia\n",
    "\n",
    "mri[\"basal_ischemia\"]  = mri[\"ba_ischemia\"] + mri[\"bas_ischemia\"] + mri[\"bis_ischemia\"] \\\n",
    "                         + mri[\"bi_ischemia\"] + mri[\"bil_ischemia\"] + mri[\"bal_ischemia\"]\n",
    "mri[\"mid_ischemia\"]    = mri[\"ma_ischemia\"] + mri[\"mas_ischemia\"] + mri[\"mis_ischemia\"] \\\n",
    "                         + mri[\"mi_ischemia\"] + mri[\"mil_ischemia\"] + mri[\"mal_ischemia\"]\n",
    "mri[\"apical_ischemia\"] = mri[\"aa_ischemia\"] + mri[\"as_ischemia\"] + mri[\"ai_ischemia\"] \\\n",
    "                         + mri[\"al_ischemia\"]\n",
    "\n",
    "print(f\"The shape of the dataset is: {mri.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-Of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be easier when modeling to have two data sets: one with the original features and one with the features I engineered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the original dataframe\n",
    "\n",
    "mri_org = mri.drop(labels = [\"lvesv_log\", \"basal_he\", \"mid_he\",\n",
    "                             \"apical_he\", \"basal_ischemia\",\n",
    "                             \"mid_ischemia\", \"apical_ischemia\"],\n",
    "                   axis = 1)\n",
    "\n",
    "# Defining the dataframe with only new features\n",
    "\n",
    "mri_eng = mri.drop(labels = ['lvesv', 'ba_he', 'bas_he', 'bis_he','bi_he', \n",
    "                             'bil_he', 'bal_he', 'ma_he', 'mas_he', 'mis_he', \n",
    "                             'mi_he', 'mil_he','mal_he', 'aa_he', 'as_he', \n",
    "                             'ai_he', 'al_he', 'apex_he', 'ba_ischemia',\n",
    "                             'bas_ischemia', 'bis_ischemia', 'bi_ischemia', \n",
    "                             'bil_ischemia','bal_ischemia', 'ma_ischemia', \n",
    "                             'mas_ischemia', 'mis_ischemia','mi_ischemia', \n",
    "                             'mil_ischemia', 'mal_ischemia', 'aa_ischemia', \n",
    "                             'as_ischemia', 'ai_ischemia', 'al_ischemia'],\n",
    "                   axis = 1)\n",
    "\n",
    "# Checking to make sure the two have different numbers of columns\n",
    "\n",
    "print(f\"The shape of the dataframe with original features is: {mri_org.shape}\")\n",
    "print(f\"The shape of the dataframe with new features is     : {mri_eng.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Table-Of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start modeling, we have to perform a train-test split.  A train-test split allows us to train our data on one subset of the dataframe and train on another subset.\n",
    "\n",
    "Since I have two versions of the dataframe, I will have to train-test split on both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up my X and y variables for the original\n",
    "\n",
    "X  = mri_org.drop(\"lvedv\", axis = 1)\n",
    "y  = mri_org[\"lvedv\"]\n",
    "\n",
    "# Setting up my X and y variables for the new\n",
    "\n",
    "X_eng = mri_eng.drop(\"lvedv\", axis = 1)\n",
    "y_eng = mri_eng[\"lvedv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test splitting mri_og\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    random_state = 42,\n",
    "                                                    test_size    = 0.25) \n",
    "\n",
    "# Train-test splitting mri_new\n",
    "\n",
    "X_train_eng, X_test_eng, y_train_eng, y_test_eng = train_test_split(X_eng, \n",
    "                                                                    y_eng,\n",
    "                                                                    random_state = 42,\n",
    "                                                                    test_size    = 0.25) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adj(X, y_true, y_predicted):\n",
    "    r2          = r2_score(y_true, y_predicted)\n",
    "    numerator   = (1 - r2) * (len(y) - 1)\n",
    "    denominator = (len(y) - len(X.columns)) - 1\n",
    "    quotient    = numerator / denominator\n",
    "    r2_adj      = 1 - quotient\n",
    "    return r2_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be my primary model evaluation\n",
    "# method for this project. \n",
    "\n",
    "def model_evaluation(X, y_true, y_predicted):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_predicted))\n",
    "    mae  = mean_absolute_error(y_true, y_predicted)\n",
    "    r2   = r2_score(y_true, y_predicted)\n",
    "    print(f\"The root mean squared error is : {rmse}\")\n",
    "    print(f\"The mean absolute error is     : {mae}\")\n",
    "    print(f\"The r2 score is                : {r2}\")\n",
    "    print(f\"The adjusted r2 score is       : {r2_adj(X, y_true, y_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_nor2adj(y_true, y_predicted):\n",
    "    rmse = sqrt(mean_squared_error(y_true, y_predicted))\n",
    "    mae  = mean_absolute_error(y_true, y_predicted)\n",
    "    r2   = r2_score(y_true, y_predicted)\n",
    "    print(f\"The root mean squared error is : {rmse}\")\n",
    "    print(f\"The mean absolute error is     : {mae}\")\n",
    "    print(f\"The r2 score is                : {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the linear regression\n",
    "\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the linear regression to the original\n",
    "# (non-engineered) subset\n",
    "\n",
    "lin_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating my predictions\n",
    "\n",
    "y_pred  = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating my original set\n",
    "\n",
    "model_evaluation(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data  = lin_reg.coef_,\n",
    "             index = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the linear regression to the subset\n",
    "# with the features I engineered\n",
    "\n",
    "lin_reg.fit(X_train_eng, y_train_eng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating my predictions\n",
    "\n",
    "y_pred_eng  = lin_reg.predict(X_test_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating my new set\n",
    "\n",
    "model_evaluation(X_test_eng, y_test_eng, y_pred_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data  = lin_reg.coef_,\n",
    "             index = X_test_eng.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression works by imposing a penalty on the coefficients.  For that reason, the data has to be scaled because small differences in the data can make the penalties enormous.  We used `StandardScaler` to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the standard scaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the original set\n",
    "\n",
    "# Fit-transforming my X_train features\n",
    "\n",
    "X_train_ss     = ss.fit_transform(X_train)\n",
    "\n",
    "# Transforming my X_test variables\n",
    "\n",
    "X_test_ss  = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the engineered set\n",
    "\n",
    "# Fit-transforming my X_train_eng features\n",
    "\n",
    "X_train_eng_ss = ss.fit_transform(X_train_eng)\n",
    "\n",
    "# Transforming my X_test_eng features\n",
    "\n",
    "X_test_eng_ss = ss.transform(X_test_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the ridge model\n",
    "\n",
    "ridge = RidgeCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ridge model to the training data\n",
    "\n",
    "ridge.fit(X_train_ss, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Predictions\n",
    "\n",
    "y_pred = ridge.predict(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_nor2adj(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ridge model to the data\n",
    "# with engineered features\n",
    "\n",
    "ridge.fit(X_train_eng_ss, y_train_eng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eng = ridge.predict(X_test_eng_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_nor2adj(y_test_eng, y_pred_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO is similar to ridge in that it also has to be scaled to work properly.  We will be using `StandardScaler` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the original set\n",
    "\n",
    "# Fit-transforming my X_train features\n",
    "\n",
    "X_train_ss     = ss.fit_transform(X_train)\n",
    "\n",
    "# Transforming my X_test variables\n",
    "\n",
    "X_test_ss  = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the engineered set\n",
    "\n",
    "# Fit-transforming my X_train_eng features\n",
    "\n",
    "X_train_eng_ss = ss.fit_transform(X_train_eng)\n",
    "\n",
    "# Transforming my X_test_eng features\n",
    "\n",
    "X_test_eng_ss = ss.transform(X_test_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the LASSO model\n",
    "\n",
    "lasso = LassoCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the lasso to my training data\n",
    "# without engineered features\n",
    "\n",
    "lasso.fit(X_train_ss, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_nor2adj(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the lasso to my training data\n",
    "# with engineered features\n",
    "\n",
    "lasso.fit(X_train_eng_ss, y_train_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eng = lasso.predict(X_test_eng_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation_nor2adj(y_test_eng, y_pred_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
